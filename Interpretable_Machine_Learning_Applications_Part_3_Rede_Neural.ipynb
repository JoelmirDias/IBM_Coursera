{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interpretable Machine Learning Applications: Part 3 - Rede Neural.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpKlC6bOsATj/B60XylbPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoelmirDias/IBM_Coursera/blob/main/Interpretable_Machine_Learning_Applications_Part_3_Rede_Neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aix360"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHr3Qwq7osjl",
        "outputId": "fa9e3e66-6f85-40d2-e810-1a40bcf9b31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aix360\n",
            "  Downloading aix360-0.2.1-py3-none-any.whl (58.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 58.3 MB 1.9 MB/s \n",
            "\u001b[?25hCollecting lime==0.1.1.37\n",
            "  Downloading lime-0.1.1.37.tar.gz (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from aix360) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from aix360) (2.23.0)\n",
            "Collecting Image\n",
            "  Downloading image-1.5.33.tar.gz (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from aix360) (1.12.0+cu113)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.0.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.7/dist-packages (from aix360) (1.2.1)\n",
            "Collecting xgboost==1.0.2\n",
            "  Downloading xgboost-1.0.2-py3-none-manylinux1_x86_64.whl (109.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.7 MB 11 kB/s \n",
            "\u001b[?25hCollecting shap==0.34.0\n",
            "  Downloading shap-0.34.0.tar.gz (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.7.3)\n",
            "Collecting keras==2.3.1\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 56.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.14\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 54 kB/s \n",
            "\u001b[?25hCollecting xport\n",
            "  Downloading xport-3.6.1-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from aix360) (0.18.3)\n",
            "Collecting qpsolvers\n",
            "  Downloading qpsolvers-2.1.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 390 kB/s \n",
            "\u001b[?25hRequirement already satisfied: bleach>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from aix360) (5.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.1.0)\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from aix360) (0.17.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from aix360) (0.13.0+cu113)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.7/dist-packages (from aix360) (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from aix360) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aix360) (3.2.2)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from aix360) (1.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (3.1.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap==0.34.0->aix360) (4.64.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.2.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 72.1 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 37.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.14.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.5.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->aix360) (0.5.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (2.9.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->aix360) (4.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->aix360) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (3.8.1)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (2.0.10)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (3.2.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (0.6.2.post0)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy->aix360) (0.1.5.post2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1->aix360) (1.5.2)\n",
            "Collecting django\n",
            "  Downloading Django-3.2.15-py3-none-any.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 23.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from django->Image->aix360) (2022.1)\n",
            "Collecting asgiref<4,>=3.3.2\n",
            "  Downloading asgiref-3.5.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from django->Image->aix360) (0.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (1.24.3)\n",
            "Requirement already satisfied: click>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from xport->aix360) (7.1.2)\n",
            "Building wheels for collected packages: lime, shap, Image, progressbar\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.1.1.37-py3-none-any.whl size=284290 sha256=37863594eef9bee3b5cf1a45003205e5ed780f76d1ae180bb7be758837358df0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/7a/8d/30e0ea15164fb80d5484e83ab991e188d6a9d8febfada307a6\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.34.0-cp37-cp37m-linux_x86_64.whl size=384443 sha256=af39b4eddc75afe7837f008d7518f886d8371ef9b1252f28634be8fbce7940bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/86/23/2c22a86fb2ba700382f20e1dbe536e211b3b1578aecc8adfac\n",
            "  Building wheel for Image (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Image: filename=image-1.5.33-py2.py3-none-any.whl size=19496 sha256=b0245f4410fb5f64bc59e670f820dc5dda43bab7288613b7ccd828b055a91f7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/88/e6/897194cfe8c08a8b9afd881d3bf53d102e13fa39607d721383\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=74b9de182583053973fbb95c3dd1a410f3acd885f11bae74d3c61b05a3ad18cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n",
            "Successfully built lime shap Image progressbar\n",
            "Installing collected packages: asgiref, tensorflow-estimator, tensorboard, progressbar, keras-applications, django, xport, xgboost, tensorflow, shap, qpsolvers, lime, keras, Image, aix360\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Image-1.5.33 aix360-0.2.1 asgiref-3.5.2 django-3.2.15 keras-2.3.1 keras-applications-1.0.8 lime-0.1.1.37 progressbar-2.5 qpsolvers-2.1.0 shap-0.34.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 xgboost-1.0.2 xport-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r368p2v2qg27",
        "outputId": "b4b3b5b2-73fb-473c-fc28-322685fb36f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SA3DxleDm9Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "R4_ZP31ck6Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model, load_model, model_from_json\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ahb6kzuOlJxY",
        "outputId": "bb5963bb-01bf-4368-c998-5a54738cfbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.display import display, HTML"
      ],
      "metadata": {
        "id": "8xRZImR6lWAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aix360.algorithms.contrastive import CEMExplainer, KerasClassifier\n",
        "from aix360.algorithms.protodash import ProtodashExplainer\n",
        "from aix360.datasets.heloc_dataset import HELOCDataset"
      ],
      "metadata": {
        "id": "j3UOY_57nuuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#arquivo heloc_dataset.csv precisa estar em /usr/local/lib/python3.7/dist-packages/aix360/data/heloc_data/heloc_dataset.csv\n",
        "heloc=HELOCDataset()\n",
        "df=heloc.dataframe()\n",
        "pd.set_option('display.max_rows',500)\n",
        "pd.set_option('display.max_columns',24)\n",
        "pd.set_option('display.width',1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMxZph4pmUs4",
        "outputId": "3ee8b05a-99ca-4ac1-8364-3f7663f2353d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Heloc dataset:  /usr/local/lib/python3.7/dist-packages/aix360/datasets/../data/heloc_data/heloc_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head().transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "ujDLH2Uzs52K",
        "outputId": "5bc1828f-4232-4327-d278-7a914a25fd1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      0    1    2    3    4\n",
              "ExternalRiskEstimate                 55   61   67   66   81\n",
              "MSinceOldestTradeOpen               144   58   66  169  333\n",
              "MSinceMostRecentTradeOpen             4   15    5    1   27\n",
              "AverageMInFile                       84   41   24   73  132\n",
              "NumSatisfactoryTrades                20    2    9   28   12\n",
              "NumTrades60Ever2DerogPubRec           3    4    0    1    0\n",
              "NumTrades90Ever2DerogPubRec           0    4    0    1    0\n",
              "PercentTradesNeverDelq               83  100  100   93  100\n",
              "MSinceMostRecentDelq                  2   -7   -7   76   -7\n",
              "MaxDelq2PublicRecLast12M              3    0    7    6    7\n",
              "MaxDelqEver                           5    8    8    6    8\n",
              "NumTotalTrades                       23    7    9   30   12\n",
              "NumTradesOpeninLast12M                1    0    4    3    0\n",
              "PercentInstallTrades                 43   67   44   57   25\n",
              "MSinceMostRecentInqexcl7days          0    0    0    0    0\n",
              "NumInqLast6M                          0    0    4    5    1\n",
              "NumInqLast6Mexcl7days                 0    0    4    4    1\n",
              "NetFractionRevolvingBurden           33    0   53   72   51\n",
              "NetFractionInstallBurden             -8   -8   66   83   89\n",
              "NumRevolvingTradesWBalance            8    0    4    6    3\n",
              "NumInstallTradesWBalance              1   -8    2    4    1\n",
              "NumBank2NatlTradesWHighUtilization    1   -8    1    3    0\n",
              "PercentTradesWBalance                69    0   86   91   80\n",
              "RiskPerformance                     Bad  Bad  Bad  Bad  Bad"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a1728d7-ab27-4706-a9c0-0e3fcd968535\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExternalRiskEstimate</th>\n",
              "      <td>55</td>\n",
              "      <td>61</td>\n",
              "      <td>67</td>\n",
              "      <td>66</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceOldestTradeOpen</th>\n",
              "      <td>144</td>\n",
              "      <td>58</td>\n",
              "      <td>66</td>\n",
              "      <td>169</td>\n",
              "      <td>333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentTradeOpen</th>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AverageMInFile</th>\n",
              "      <td>84</td>\n",
              "      <td>41</td>\n",
              "      <td>24</td>\n",
              "      <td>73</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSatisfactoryTrades</th>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades60Ever2DerogPubRec</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades90Ever2DerogPubRec</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesNeverDelq</th>\n",
              "      <td>83</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>93</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentDelq</th>\n",
              "      <td>2</td>\n",
              "      <td>-7</td>\n",
              "      <td>-7</td>\n",
              "      <td>76</td>\n",
              "      <td>-7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelq2PublicRecLast12M</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelqEver</th>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTotalTrades</th>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTradesOpeninLast12M</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentInstallTrades</th>\n",
              "      <td>43</td>\n",
              "      <td>67</td>\n",
              "      <td>44</td>\n",
              "      <td>57</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentInqexcl7days</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6M</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6Mexcl7days</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionRevolvingBurden</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>72</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionInstallBurden</th>\n",
              "      <td>-8</td>\n",
              "      <td>-8</td>\n",
              "      <td>66</td>\n",
              "      <td>83</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRevolvingTradesWBalance</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInstallTradesWBalance</th>\n",
              "      <td>1</td>\n",
              "      <td>-8</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
              "      <td>1</td>\n",
              "      <td>-8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesWBalance</th>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>91</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RiskPerformance</th>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a1728d7-ab27-4706-a9c0-0e3fcd968535')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a1728d7-ab27-4706-a9c0-0e3fcd968535 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a1728d7-ab27-4706-a9c0-0e3fcd968535');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of HELOC dataset:\", df.shape)\n",
        "print(\"Number of \\\"Good\\\" applicants:\", np.sum(df['RiskPerformance']=='Good'))\n",
        "print(\"Number of \\\"Bad\\\" applicants:\", np.sum(df['RiskPerformance']=='Bad'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdEC15lxveTV",
        "outputId": "6703015d-8e32-4b4e-8cd6-f11a16cd13f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of HELOC dataset: (10459, 24)\n",
            "Number of \"Good\" applicants: 5000\n",
            "Number of \"Bad\" applicants: 5459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(column=['ExternalRiskEstimate'], bins=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "lBW2uTaMwRbK",
        "outputId": "897fafc2-3b90-4c12-8a84-4601d0c93c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f5800694610>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(column=['NetFractionInstallBurden'], bins=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "AVlarDWFxKo7",
        "outputId": "d06fedc1-67d5-458c-9c30-088aac5d249f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f58006bbb90>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(Data, x_train, x_test, y_train_b, y_test_b)=heloc.split()"
      ],
      "metadata": {
        "id": "hXAo6P2xxeuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z=np.vstack((x_train, x_test))\n",
        "Zmax=np.max(Z, axis=0)\n",
        "Zmin=np.min(Z, axis=0)"
      ],
      "metadata": {
        "id": "s1ZJ7lIqzyuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(V):\n",
        "  VN=(V-Zmin)/(Zmax-Zmin)\n",
        "  VN=VN-0.5\n",
        "  return(VN)"
      ],
      "metadata": {
        "id": "6o64AiVj0CMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalize(x_train[0:1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI3Jhrja0wIg",
        "outputId": "c6972b9d-795a-4440-9320-8a0b264b0ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.18085106 -0.28206725 -0.4843342  -0.25461741 -0.13291139 -0.02631579\n",
            "  -0.02631579  0.13       -0.47590361 -0.05555556 -0.16666667 -0.10576923\n",
            "  -0.44736842  0.13       -0.5        -0.48484848 -0.48484848 -0.43103448\n",
            "  -0.30042463 -0.46875    -0.45652174 -0.5         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N=normalize(Z)\n",
        "xn_train=N[0:x_train.shape[0],:]\n",
        "xn_test=N[x_train.shape[0]:,:]"
      ],
      "metadata": {
        "id": "9gAxsHMS1Fqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_small():\n",
        "  model=Sequential()\n",
        "  model.add(Dense(10, input_dim=23, kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(2, kernel_initializer='normal'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "9yXL0Tk22M1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "tf.set_random_seed(2)\n",
        "\n",
        "class_names=['Bad','Good']"
      ],
      "metadata": {
        "id": "5mk3K0is23Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fn(correct, predicted):\n",
        "  return tf.nn.softmax_cross_entropy_with_logits(labels=correct, logits=predicted)"
      ],
      "metadata": {
        "id": "3EgowasB3Ost"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn=nn_small()\n",
        "nn.compile(loss=fn, optimizer='adam', metrics=['accuracy'])\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mzfK1Qu3l60",
        "outputId": "21a7e327-dc80-43fd-9c4c-befa9bf6898d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-ca902273a655>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 10)                240       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 262\n",
            "Trainable params: 262\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.fit(xn_train, y_train_b, batch_size=128, epochs=500, verbose=1, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeC_OcaT4HRe",
        "outputId": "0a15813e-58d8-44a7-8ae8-5b9e08a2d5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/500\n",
            "7403/7403 [==============================] - 0s 32us/step - loss: 0.6878 - accuracy: 0.5340\n",
            "Epoch 2/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.6638 - accuracy: 0.6416\n",
            "Epoch 3/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.6240 - accuracy: 0.6996\n",
            "Epoch 4/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5929 - accuracy: 0.7094\n",
            "Epoch 5/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5765 - accuracy: 0.7131\n",
            "Epoch 6/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5679 - accuracy: 0.7196\n",
            "Epoch 7/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5626 - accuracy: 0.7219\n",
            "Epoch 8/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5591 - accuracy: 0.7252\n",
            "Epoch 9/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5566 - accuracy: 0.7248\n",
            "Epoch 10/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5546 - accuracy: 0.7267\n",
            "Epoch 11/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5531 - accuracy: 0.7278\n",
            "Epoch 12/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5519 - accuracy: 0.7284\n",
            "Epoch 13/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5509 - accuracy: 0.7279\n",
            "Epoch 14/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5501 - accuracy: 0.7282\n",
            "Epoch 15/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5494 - accuracy: 0.7297\n",
            "Epoch 16/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5488 - accuracy: 0.7306\n",
            "Epoch 17/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5482 - accuracy: 0.7312\n",
            "Epoch 18/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5477 - accuracy: 0.7315\n",
            "Epoch 19/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5473 - accuracy: 0.7319\n",
            "Epoch 20/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5469 - accuracy: 0.7308\n",
            "Epoch 21/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5466 - accuracy: 0.7309\n",
            "Epoch 22/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5463 - accuracy: 0.7312\n",
            "Epoch 23/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5460 - accuracy: 0.7311\n",
            "Epoch 24/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5458 - accuracy: 0.7311\n",
            "Epoch 25/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5455 - accuracy: 0.7313\n",
            "Epoch 26/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5453 - accuracy: 0.7312\n",
            "Epoch 27/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5451 - accuracy: 0.7315\n",
            "Epoch 28/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5449 - accuracy: 0.7317\n",
            "Epoch 29/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5447 - accuracy: 0.7320\n",
            "Epoch 30/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5445 - accuracy: 0.7321\n",
            "Epoch 31/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5443 - accuracy: 0.7327\n",
            "Epoch 32/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5442 - accuracy: 0.7332\n",
            "Epoch 33/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5440 - accuracy: 0.7335\n",
            "Epoch 34/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5439 - accuracy: 0.7335\n",
            "Epoch 35/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5437 - accuracy: 0.7338\n",
            "Epoch 36/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5436 - accuracy: 0.7339\n",
            "Epoch 37/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5435 - accuracy: 0.7342\n",
            "Epoch 38/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5433 - accuracy: 0.7340\n",
            "Epoch 39/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5432 - accuracy: 0.7338\n",
            "Epoch 40/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5431 - accuracy: 0.7329\n",
            "Epoch 41/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5430 - accuracy: 0.7328\n",
            "Epoch 42/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5429 - accuracy: 0.7331\n",
            "Epoch 43/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5428 - accuracy: 0.7336\n",
            "Epoch 44/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5428 - accuracy: 0.7339\n",
            "Epoch 45/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5427 - accuracy: 0.7342\n",
            "Epoch 46/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5426 - accuracy: 0.7342\n",
            "Epoch 47/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5425 - accuracy: 0.7342\n",
            "Epoch 48/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5424 - accuracy: 0.7343\n",
            "Epoch 49/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5424 - accuracy: 0.7343\n",
            "Epoch 50/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5423 - accuracy: 0.7342\n",
            "Epoch 51/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5422 - accuracy: 0.7340\n",
            "Epoch 52/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5422 - accuracy: 0.7339\n",
            "Epoch 53/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5421 - accuracy: 0.7335\n",
            "Epoch 54/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5420 - accuracy: 0.7338\n",
            "Epoch 55/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5420 - accuracy: 0.7339\n",
            "Epoch 56/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5419 - accuracy: 0.7340\n",
            "Epoch 57/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5418 - accuracy: 0.7339\n",
            "Epoch 58/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5418 - accuracy: 0.7339\n",
            "Epoch 59/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5417 - accuracy: 0.7342\n",
            "Epoch 60/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5416 - accuracy: 0.7342\n",
            "Epoch 61/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5416 - accuracy: 0.7343\n",
            "Epoch 62/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5415 - accuracy: 0.7344\n",
            "Epoch 63/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5415 - accuracy: 0.7343\n",
            "Epoch 64/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5414 - accuracy: 0.7344\n",
            "Epoch 65/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5414 - accuracy: 0.7347\n",
            "Epoch 66/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5413 - accuracy: 0.7346\n",
            "Epoch 67/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5413 - accuracy: 0.7346\n",
            "Epoch 68/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5412 - accuracy: 0.7351\n",
            "Epoch 69/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5412 - accuracy: 0.7348\n",
            "Epoch 70/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5411 - accuracy: 0.7346\n",
            "Epoch 71/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5411 - accuracy: 0.7346\n",
            "Epoch 72/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5410 - accuracy: 0.7344\n",
            "Epoch 73/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5410 - accuracy: 0.7344\n",
            "Epoch 74/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5409 - accuracy: 0.7343\n",
            "Epoch 75/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5409 - accuracy: 0.7342\n",
            "Epoch 76/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5408 - accuracy: 0.7344\n",
            "Epoch 77/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5407 - accuracy: 0.7343\n",
            "Epoch 78/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5407 - accuracy: 0.7336\n",
            "Epoch 79/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5406 - accuracy: 0.7336\n",
            "Epoch 80/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5405 - accuracy: 0.7335\n",
            "Epoch 81/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5405 - accuracy: 0.7335\n",
            "Epoch 82/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5404 - accuracy: 0.7339\n",
            "Epoch 83/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5404 - accuracy: 0.7340\n",
            "Epoch 84/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5403 - accuracy: 0.7339\n",
            "Epoch 85/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5403 - accuracy: 0.7342\n",
            "Epoch 86/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5402 - accuracy: 0.7340\n",
            "Epoch 87/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5402 - accuracy: 0.7340\n",
            "Epoch 88/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5401 - accuracy: 0.7339\n",
            "Epoch 89/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5401 - accuracy: 0.7342\n",
            "Epoch 90/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5400 - accuracy: 0.7339\n",
            "Epoch 91/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5400 - accuracy: 0.7347\n",
            "Epoch 92/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5399 - accuracy: 0.7346\n",
            "Epoch 93/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5399 - accuracy: 0.7348\n",
            "Epoch 94/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5398 - accuracy: 0.7346\n",
            "Epoch 95/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5398 - accuracy: 0.7348\n",
            "Epoch 96/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5397 - accuracy: 0.7346\n",
            "Epoch 97/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5397 - accuracy: 0.7344\n",
            "Epoch 98/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5397 - accuracy: 0.7343\n",
            "Epoch 99/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5396 - accuracy: 0.7342\n",
            "Epoch 100/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5396 - accuracy: 0.7343\n",
            "Epoch 101/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5395 - accuracy: 0.7346\n",
            "Epoch 102/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5395 - accuracy: 0.7346\n",
            "Epoch 103/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5394 - accuracy: 0.7350\n",
            "Epoch 104/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5394 - accuracy: 0.7351\n",
            "Epoch 105/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5393 - accuracy: 0.7351\n",
            "Epoch 106/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5393 - accuracy: 0.7352\n",
            "Epoch 107/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5393 - accuracy: 0.7352\n",
            "Epoch 108/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5392 - accuracy: 0.7354\n",
            "Epoch 109/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5392 - accuracy: 0.7346\n",
            "Epoch 110/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5391 - accuracy: 0.7351\n",
            "Epoch 111/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5391 - accuracy: 0.7344\n",
            "Epoch 112/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5390 - accuracy: 0.7347\n",
            "Epoch 113/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5390 - accuracy: 0.7343\n",
            "Epoch 114/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5389 - accuracy: 0.7344\n",
            "Epoch 115/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5389 - accuracy: 0.7344\n",
            "Epoch 116/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5388 - accuracy: 0.7342\n",
            "Epoch 117/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5388 - accuracy: 0.7339\n",
            "Epoch 118/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5387 - accuracy: 0.7338\n",
            "Epoch 119/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5387 - accuracy: 0.7338\n",
            "Epoch 120/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5386 - accuracy: 0.7338\n",
            "Epoch 121/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5386 - accuracy: 0.7340\n",
            "Epoch 122/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5385 - accuracy: 0.7339\n",
            "Epoch 123/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5385 - accuracy: 0.7338\n",
            "Epoch 124/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5384 - accuracy: 0.7338\n",
            "Epoch 125/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5384 - accuracy: 0.7339\n",
            "Epoch 126/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5383 - accuracy: 0.7342\n",
            "Epoch 127/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5383 - accuracy: 0.7343\n",
            "Epoch 128/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5382 - accuracy: 0.7340\n",
            "Epoch 129/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5382 - accuracy: 0.7343\n",
            "Epoch 130/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5381 - accuracy: 0.7342\n",
            "Epoch 131/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5381 - accuracy: 0.7342\n",
            "Epoch 132/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5380 - accuracy: 0.7338\n",
            "Epoch 133/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5380 - accuracy: 0.7338\n",
            "Epoch 134/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5380 - accuracy: 0.7336\n",
            "Epoch 135/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5379 - accuracy: 0.7339\n",
            "Epoch 136/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5379 - accuracy: 0.7339\n",
            "Epoch 137/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5378 - accuracy: 0.7342\n",
            "Epoch 138/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5378 - accuracy: 0.7344\n",
            "Epoch 139/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5378 - accuracy: 0.7344\n",
            "Epoch 140/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5377 - accuracy: 0.7343\n",
            "Epoch 141/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5376 - accuracy: 0.7339\n",
            "Epoch 142/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5376 - accuracy: 0.7343\n",
            "Epoch 143/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5376 - accuracy: 0.7339\n",
            "Epoch 144/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5375 - accuracy: 0.7340\n",
            "Epoch 145/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5375 - accuracy: 0.7342\n",
            "Epoch 146/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5374 - accuracy: 0.7342\n",
            "Epoch 147/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5374 - accuracy: 0.7343\n",
            "Epoch 148/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5373 - accuracy: 0.7340\n",
            "Epoch 149/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5373 - accuracy: 0.7343\n",
            "Epoch 150/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5373 - accuracy: 0.7347\n",
            "Epoch 151/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5372 - accuracy: 0.7344\n",
            "Epoch 152/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5372 - accuracy: 0.7348\n",
            "Epoch 153/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5372 - accuracy: 0.7346\n",
            "Epoch 154/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5371 - accuracy: 0.7348\n",
            "Epoch 155/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5371 - accuracy: 0.7348\n",
            "Epoch 156/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5371 - accuracy: 0.7344\n",
            "Epoch 157/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5370 - accuracy: 0.7343\n",
            "Epoch 158/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5370 - accuracy: 0.7342\n",
            "Epoch 159/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5370 - accuracy: 0.7343\n",
            "Epoch 160/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5369 - accuracy: 0.7350\n",
            "Epoch 161/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5369 - accuracy: 0.7348\n",
            "Epoch 162/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5369 - accuracy: 0.7347\n",
            "Epoch 163/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5369 - accuracy: 0.7351\n",
            "Epoch 164/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5368 - accuracy: 0.7354\n",
            "Epoch 165/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5368 - accuracy: 0.7354\n",
            "Epoch 166/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5368 - accuracy: 0.7352\n",
            "Epoch 167/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5368 - accuracy: 0.7352\n",
            "Epoch 168/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5367 - accuracy: 0.7350\n",
            "Epoch 169/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5367 - accuracy: 0.7347\n",
            "Epoch 170/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5367 - accuracy: 0.7347\n",
            "Epoch 171/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5367 - accuracy: 0.7347\n",
            "Epoch 172/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5366 - accuracy: 0.7350\n",
            "Epoch 173/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5366 - accuracy: 0.7347\n",
            "Epoch 174/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5366 - accuracy: 0.7348\n",
            "Epoch 175/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5366 - accuracy: 0.7351\n",
            "Epoch 176/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5366 - accuracy: 0.7344\n",
            "Epoch 177/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5365 - accuracy: 0.7342\n",
            "Epoch 178/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5365 - accuracy: 0.7348\n",
            "Epoch 179/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5365 - accuracy: 0.7343\n",
            "Epoch 180/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5365 - accuracy: 0.7346\n",
            "Epoch 181/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5364 - accuracy: 0.7351\n",
            "Epoch 182/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5364 - accuracy: 0.7352\n",
            "Epoch 183/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5364 - accuracy: 0.7350\n",
            "Epoch 184/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5364 - accuracy: 0.7354\n",
            "Epoch 185/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5364 - accuracy: 0.7355\n",
            "Epoch 186/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5363 - accuracy: 0.7352\n",
            "Epoch 187/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5363 - accuracy: 0.7358\n",
            "Epoch 188/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5363 - accuracy: 0.7356\n",
            "Epoch 189/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5363 - accuracy: 0.7358\n",
            "Epoch 190/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5363 - accuracy: 0.7356\n",
            "Epoch 191/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7356\n",
            "Epoch 192/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7358\n",
            "Epoch 193/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7358\n",
            "Epoch 194/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7358\n",
            "Epoch 195/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5362 - accuracy: 0.7358\n",
            "Epoch 196/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5361 - accuracy: 0.7358\n",
            "Epoch 197/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5361 - accuracy: 0.7354\n",
            "Epoch 198/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5361 - accuracy: 0.7355\n",
            "Epoch 199/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5361 - accuracy: 0.7351\n",
            "Epoch 200/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5361 - accuracy: 0.7354\n",
            "Epoch 201/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5360 - accuracy: 0.7355\n",
            "Epoch 202/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5360 - accuracy: 0.7354\n",
            "Epoch 203/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5360 - accuracy: 0.7354\n",
            "Epoch 204/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5360 - accuracy: 0.7355\n",
            "Epoch 205/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5360 - accuracy: 0.7355\n",
            "Epoch 206/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5360 - accuracy: 0.7356\n",
            "Epoch 207/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5359 - accuracy: 0.7356\n",
            "Epoch 208/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7354\n",
            "Epoch 209/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5359 - accuracy: 0.7356\n",
            "Epoch 210/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7358\n",
            "Epoch 211/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5359 - accuracy: 0.7354\n",
            "Epoch 212/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5359 - accuracy: 0.7356\n",
            "Epoch 213/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7355\n",
            "Epoch 214/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5358 - accuracy: 0.7358\n",
            "Epoch 215/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5358 - accuracy: 0.7355\n",
            "Epoch 216/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7352\n",
            "Epoch 217/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5358 - accuracy: 0.7351\n",
            "Epoch 218/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5358 - accuracy: 0.7352\n",
            "Epoch 219/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5358 - accuracy: 0.7351\n",
            "Epoch 220/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5358 - accuracy: 0.7352\n",
            "Epoch 221/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5358 - accuracy: 0.7352\n",
            "Epoch 222/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5358 - accuracy: 0.7352\n",
            "Epoch 223/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5357 - accuracy: 0.7354\n",
            "Epoch 224/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7351\n",
            "Epoch 225/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7352\n",
            "Epoch 226/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7352\n",
            "Epoch 227/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5357 - accuracy: 0.7352\n",
            "Epoch 228/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7350\n",
            "Epoch 229/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5357 - accuracy: 0.7350\n",
            "Epoch 230/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5357 - accuracy: 0.7352\n",
            "Epoch 231/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5356 - accuracy: 0.7352\n",
            "Epoch 232/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5356 - accuracy: 0.7351\n",
            "Epoch 233/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5356 - accuracy: 0.7352\n",
            "Epoch 234/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5356 - accuracy: 0.7352\n",
            "Epoch 235/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5356 - accuracy: 0.7354\n",
            "Epoch 236/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5356 - accuracy: 0.7354\n",
            "Epoch 237/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5356 - accuracy: 0.7354\n",
            "Epoch 238/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5355 - accuracy: 0.7351\n",
            "Epoch 239/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7352\n",
            "Epoch 240/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7352\n",
            "Epoch 241/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5355 - accuracy: 0.7354\n",
            "Epoch 242/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7351\n",
            "Epoch 243/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5355 - accuracy: 0.7352\n",
            "Epoch 244/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7352\n",
            "Epoch 245/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7348\n",
            "Epoch 246/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5354 - accuracy: 0.7347\n",
            "Epoch 247/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5354 - accuracy: 0.7350\n",
            "Epoch 248/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5354 - accuracy: 0.7350\n",
            "Epoch 249/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5354 - accuracy: 0.7350\n",
            "Epoch 250/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5354 - accuracy: 0.7347\n",
            "Epoch 251/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5354 - accuracy: 0.7351\n",
            "Epoch 252/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5354 - accuracy: 0.7347\n",
            "Epoch 253/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5353 - accuracy: 0.7348\n",
            "Epoch 254/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5353 - accuracy: 0.7350\n",
            "Epoch 255/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5353 - accuracy: 0.7348\n",
            "Epoch 256/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5353 - accuracy: 0.7348\n",
            "Epoch 257/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5353 - accuracy: 0.7351\n",
            "Epoch 258/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5353 - accuracy: 0.7351\n",
            "Epoch 259/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5352 - accuracy: 0.7352\n",
            "Epoch 260/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5352 - accuracy: 0.7352\n",
            "Epoch 261/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5352 - accuracy: 0.7355\n",
            "Epoch 262/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5351 - accuracy: 0.7351\n",
            "Epoch 263/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5351 - accuracy: 0.7354\n",
            "Epoch 264/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5351 - accuracy: 0.7356\n",
            "Epoch 265/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5350 - accuracy: 0.7355\n",
            "Epoch 266/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5349 - accuracy: 0.7355\n",
            "Epoch 267/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5349 - accuracy: 0.7359\n",
            "Epoch 268/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5348 - accuracy: 0.7359\n",
            "Epoch 269/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5348 - accuracy: 0.7361\n",
            "Epoch 270/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5347 - accuracy: 0.7359\n",
            "Epoch 271/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5347 - accuracy: 0.7359\n",
            "Epoch 272/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5346 - accuracy: 0.7362\n",
            "Epoch 273/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5346 - accuracy: 0.7365\n",
            "Epoch 274/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5345 - accuracy: 0.7366\n",
            "Epoch 275/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5345 - accuracy: 0.7367\n",
            "Epoch 276/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5344 - accuracy: 0.7366\n",
            "Epoch 277/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5343 - accuracy: 0.7361\n",
            "Epoch 278/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5343 - accuracy: 0.7359\n",
            "Epoch 279/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5342 - accuracy: 0.7358\n",
            "Epoch 280/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5341 - accuracy: 0.7359\n",
            "Epoch 281/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5340 - accuracy: 0.7356\n",
            "Epoch 282/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5339 - accuracy: 0.7358\n",
            "Epoch 283/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5338 - accuracy: 0.7354\n",
            "Epoch 284/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5337 - accuracy: 0.7355\n",
            "Epoch 285/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5336 - accuracy: 0.7361\n",
            "Epoch 286/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5335 - accuracy: 0.7365\n",
            "Epoch 287/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5335 - accuracy: 0.7361\n",
            "Epoch 288/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5335 - accuracy: 0.7361\n",
            "Epoch 289/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5334 - accuracy: 0.7367\n",
            "Epoch 290/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5333 - accuracy: 0.7361\n",
            "Epoch 291/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5333 - accuracy: 0.7359\n",
            "Epoch 292/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5332 - accuracy: 0.7356\n",
            "Epoch 293/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5332 - accuracy: 0.7351\n",
            "Epoch 294/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5331 - accuracy: 0.7354\n",
            "Epoch 295/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5331 - accuracy: 0.7352\n",
            "Epoch 296/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5331 - accuracy: 0.7358\n",
            "Epoch 297/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5330 - accuracy: 0.7358\n",
            "Epoch 298/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5330 - accuracy: 0.7359\n",
            "Epoch 299/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5330 - accuracy: 0.7359\n",
            "Epoch 300/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5329 - accuracy: 0.7356\n",
            "Epoch 301/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5329 - accuracy: 0.7355\n",
            "Epoch 302/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5328 - accuracy: 0.7359\n",
            "Epoch 303/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5328 - accuracy: 0.7363\n",
            "Epoch 304/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5327 - accuracy: 0.7367\n",
            "Epoch 305/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5327 - accuracy: 0.7369\n",
            "Epoch 306/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5327 - accuracy: 0.7369\n",
            "Epoch 307/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5326 - accuracy: 0.7366\n",
            "Epoch 308/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5326 - accuracy: 0.7365\n",
            "Epoch 309/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5326 - accuracy: 0.7362\n",
            "Epoch 310/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5325 - accuracy: 0.7362\n",
            "Epoch 311/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5325 - accuracy: 0.7367\n",
            "Epoch 312/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5324 - accuracy: 0.7369\n",
            "Epoch 313/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5324 - accuracy: 0.7370\n",
            "Epoch 314/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5324 - accuracy: 0.7374\n",
            "Epoch 315/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5323 - accuracy: 0.7373\n",
            "Epoch 316/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5323 - accuracy: 0.7373\n",
            "Epoch 317/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5323 - accuracy: 0.7373\n",
            "Epoch 318/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5322 - accuracy: 0.7371\n",
            "Epoch 319/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5322 - accuracy: 0.7370\n",
            "Epoch 320/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5322 - accuracy: 0.7370\n",
            "Epoch 321/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5321 - accuracy: 0.7369\n",
            "Epoch 322/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5321 - accuracy: 0.7369\n",
            "Epoch 323/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5321 - accuracy: 0.7369\n",
            "Epoch 324/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5321 - accuracy: 0.7365\n",
            "Epoch 325/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5320 - accuracy: 0.7366\n",
            "Epoch 326/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5320 - accuracy: 0.7369\n",
            "Epoch 327/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5320 - accuracy: 0.7370\n",
            "Epoch 328/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5320 - accuracy: 0.7370\n",
            "Epoch 329/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5319 - accuracy: 0.7371\n",
            "Epoch 330/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5319 - accuracy: 0.7363\n",
            "Epoch 331/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5319 - accuracy: 0.7362\n",
            "Epoch 332/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5319 - accuracy: 0.7366\n",
            "Epoch 333/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5318 - accuracy: 0.7365\n",
            "Epoch 334/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5318 - accuracy: 0.7363\n",
            "Epoch 335/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5318 - accuracy: 0.7363\n",
            "Epoch 336/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5318 - accuracy: 0.7362\n",
            "Epoch 337/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5318 - accuracy: 0.7363\n",
            "Epoch 338/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5317 - accuracy: 0.7363\n",
            "Epoch 339/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5317 - accuracy: 0.7363\n",
            "Epoch 340/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5317 - accuracy: 0.7363\n",
            "Epoch 341/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5317 - accuracy: 0.7363\n",
            "Epoch 342/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5317 - accuracy: 0.7363\n",
            "Epoch 343/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5316 - accuracy: 0.7362\n",
            "Epoch 344/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5316 - accuracy: 0.7362\n",
            "Epoch 345/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5316 - accuracy: 0.7361\n",
            "Epoch 346/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5316 - accuracy: 0.7359\n",
            "Epoch 347/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5316 - accuracy: 0.7358\n",
            "Epoch 348/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5316 - accuracy: 0.7361\n",
            "Epoch 349/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5315 - accuracy: 0.7358\n",
            "Epoch 350/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5315 - accuracy: 0.7361\n",
            "Epoch 351/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5315 - accuracy: 0.7359\n",
            "Epoch 352/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5315 - accuracy: 0.7359\n",
            "Epoch 353/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5315 - accuracy: 0.7359\n",
            "Epoch 354/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5315 - accuracy: 0.7356\n",
            "Epoch 355/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5315 - accuracy: 0.7358\n",
            "Epoch 356/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5314 - accuracy: 0.7359\n",
            "Epoch 357/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7356\n",
            "Epoch 358/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7358\n",
            "Epoch 359/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5314 - accuracy: 0.7356\n",
            "Epoch 360/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7356\n",
            "Epoch 361/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7356\n",
            "Epoch 362/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7355\n",
            "Epoch 363/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5313 - accuracy: 0.7354\n",
            "Epoch 364/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5313 - accuracy: 0.7354\n",
            "Epoch 365/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5313 - accuracy: 0.7355\n",
            "Epoch 366/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5313 - accuracy: 0.7355\n",
            "Epoch 367/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5313 - accuracy: 0.7355\n",
            "Epoch 368/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5312 - accuracy: 0.7355\n",
            "Epoch 369/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5312 - accuracy: 0.7354\n",
            "Epoch 370/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5312 - accuracy: 0.7355\n",
            "Epoch 371/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5312 - accuracy: 0.7354\n",
            "Epoch 372/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5312 - accuracy: 0.7355\n",
            "Epoch 373/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5312 - accuracy: 0.7356\n",
            "Epoch 374/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5312 - accuracy: 0.7354\n",
            "Epoch 375/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5312 - accuracy: 0.7355\n",
            "Epoch 376/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5312 - accuracy: 0.7354\n",
            "Epoch 377/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5312 - accuracy: 0.7355\n",
            "Epoch 378/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5311 - accuracy: 0.7358\n",
            "Epoch 379/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5311 - accuracy: 0.7358\n",
            "Epoch 380/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5311 - accuracy: 0.7358\n",
            "Epoch 381/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5311 - accuracy: 0.7355\n",
            "Epoch 382/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5311 - accuracy: 0.7359\n",
            "Epoch 383/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5311 - accuracy: 0.7354\n",
            "Epoch 384/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5311 - accuracy: 0.7355\n",
            "Epoch 385/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5311 - accuracy: 0.7355\n",
            "Epoch 386/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5311 - accuracy: 0.7355\n",
            "Epoch 387/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5310 - accuracy: 0.7358\n",
            "Epoch 388/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5310 - accuracy: 0.7358\n",
            "Epoch 389/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5310 - accuracy: 0.7355\n",
            "Epoch 390/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5310 - accuracy: 0.7356\n",
            "Epoch 391/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5310 - accuracy: 0.7358\n",
            "Epoch 392/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5310 - accuracy: 0.7358\n",
            "Epoch 393/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5310 - accuracy: 0.7356\n",
            "Epoch 394/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5309 - accuracy: 0.7356\n",
            "Epoch 395/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5309 - accuracy: 0.7356\n",
            "Epoch 396/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5309 - accuracy: 0.7359\n",
            "Epoch 397/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5309 - accuracy: 0.7356\n",
            "Epoch 398/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5309 - accuracy: 0.7356\n",
            "Epoch 399/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5309 - accuracy: 0.7355\n",
            "Epoch 400/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5308 - accuracy: 0.7359\n",
            "Epoch 401/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5308 - accuracy: 0.7359\n",
            "Epoch 402/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5308 - accuracy: 0.7358\n",
            "Epoch 403/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5308 - accuracy: 0.7356\n",
            "Epoch 404/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5308 - accuracy: 0.7359\n",
            "Epoch 405/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5307 - accuracy: 0.7362\n",
            "Epoch 406/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5307 - accuracy: 0.7358\n",
            "Epoch 407/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5307 - accuracy: 0.7358\n",
            "Epoch 408/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5307 - accuracy: 0.7358\n",
            "Epoch 409/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5307 - accuracy: 0.7361\n",
            "Epoch 410/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5307 - accuracy: 0.7362\n",
            "Epoch 411/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5307 - accuracy: 0.7361\n",
            "Epoch 412/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5306 - accuracy: 0.7356\n",
            "Epoch 413/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5306 - accuracy: 0.7356\n",
            "Epoch 414/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5306 - accuracy: 0.7356\n",
            "Epoch 415/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5306 - accuracy: 0.7359\n",
            "Epoch 416/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5305 - accuracy: 0.7362\n",
            "Epoch 417/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5305 - accuracy: 0.7359\n",
            "Epoch 418/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5305 - accuracy: 0.7358\n",
            "Epoch 419/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5305 - accuracy: 0.7365\n",
            "Epoch 420/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5305 - accuracy: 0.7363\n",
            "Epoch 421/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5305 - accuracy: 0.7365\n",
            "Epoch 422/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5305 - accuracy: 0.7366\n",
            "Epoch 423/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5304 - accuracy: 0.7367\n",
            "Epoch 424/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5304 - accuracy: 0.7366\n",
            "Epoch 425/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5304 - accuracy: 0.7367\n",
            "Epoch 426/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5304 - accuracy: 0.7370\n",
            "Epoch 427/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5304 - accuracy: 0.7369\n",
            "Epoch 428/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5304 - accuracy: 0.7369\n",
            "Epoch 429/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5303 - accuracy: 0.7369\n",
            "Epoch 430/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5303 - accuracy: 0.7367\n",
            "Epoch 431/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5303 - accuracy: 0.7370\n",
            "Epoch 432/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5303 - accuracy: 0.7373\n",
            "Epoch 433/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5303 - accuracy: 0.7371\n",
            "Epoch 434/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5302 - accuracy: 0.7371\n",
            "Epoch 435/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5302 - accuracy: 0.7370\n",
            "Epoch 436/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5302 - accuracy: 0.7370\n",
            "Epoch 437/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5302 - accuracy: 0.7369\n",
            "Epoch 438/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5302 - accuracy: 0.7370\n",
            "Epoch 439/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5302 - accuracy: 0.7370\n",
            "Epoch 440/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5302 - accuracy: 0.7373\n",
            "Epoch 441/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5301 - accuracy: 0.7369\n",
            "Epoch 442/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5301 - accuracy: 0.7370\n",
            "Epoch 443/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5301 - accuracy: 0.7369\n",
            "Epoch 444/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5301 - accuracy: 0.7369\n",
            "Epoch 445/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5301 - accuracy: 0.7369\n",
            "Epoch 446/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5301 - accuracy: 0.7367\n",
            "Epoch 447/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5301 - accuracy: 0.7369\n",
            "Epoch 448/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7367\n",
            "Epoch 449/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7370\n",
            "Epoch 450/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7367\n",
            "Epoch 451/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7369\n",
            "Epoch 452/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7369\n",
            "Epoch 453/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5300 - accuracy: 0.7369\n",
            "Epoch 454/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5300 - accuracy: 0.7367\n",
            "Epoch 455/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5300 - accuracy: 0.7367\n",
            "Epoch 456/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5300 - accuracy: 0.7371\n",
            "Epoch 457/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5300 - accuracy: 0.7370\n",
            "Epoch 458/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7371\n",
            "Epoch 459/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7370\n",
            "Epoch 460/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7370\n",
            "Epoch 461/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5299 - accuracy: 0.7370\n",
            "Epoch 462/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5299 - accuracy: 0.7371\n",
            "Epoch 463/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7370\n",
            "Epoch 464/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7371\n",
            "Epoch 465/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5299 - accuracy: 0.7373\n",
            "Epoch 466/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5299 - accuracy: 0.7371\n",
            "Epoch 467/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5299 - accuracy: 0.7373\n",
            "Epoch 468/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7373\n",
            "Epoch 469/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5299 - accuracy: 0.7374\n",
            "Epoch 470/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5299 - accuracy: 0.7371\n",
            "Epoch 471/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5299 - accuracy: 0.7371\n",
            "Epoch 472/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7375\n",
            "Epoch 473/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7374\n",
            "Epoch 474/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7373\n",
            "Epoch 475/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7377\n",
            "Epoch 476/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7377\n",
            "Epoch 477/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7375\n",
            "Epoch 478/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5298 - accuracy: 0.7374\n",
            "Epoch 479/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7377\n",
            "Epoch 480/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5298 - accuracy: 0.7377\n",
            "Epoch 481/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7377\n",
            "Epoch 482/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7377\n",
            "Epoch 483/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7379\n",
            "Epoch 484/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7378\n",
            "Epoch 485/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5297 - accuracy: 0.7379\n",
            "Epoch 486/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7379\n",
            "Epoch 487/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7379\n",
            "Epoch 488/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5297 - accuracy: 0.7379\n",
            "Epoch 489/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7383\n",
            "Epoch 490/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7381\n",
            "Epoch 491/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7381\n",
            "Epoch 492/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5297 - accuracy: 0.7379\n",
            "Epoch 493/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5297 - accuracy: 0.7377\n",
            "Epoch 494/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7381\n",
            "Epoch 495/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5297 - accuracy: 0.7379\n",
            "Epoch 496/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5296 - accuracy: 0.7382\n",
            "Epoch 497/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5296 - accuracy: 0.7377\n",
            "Epoch 498/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5296 - accuracy: 0.7383\n",
            "Epoch 499/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5296 - accuracy: 0.7381\n",
            "Epoch 500/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5296 - accuracy: 0.7379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f58005ec490>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score=nn.evaluate(xn_test,y_test_b,verbose=0)\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnDnDDLu5U1W",
        "outputId": "8bfc9fcd-c22a-4964-c653-259eb9594b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7204213738441467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_test=nn.predict_classes(xn_test)\n",
        "p_test=p_test.reshape((p_test.shape[0],1))"
      ],
      "metadata": {
        "id": "15LLCG-gh_j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_test=np.hstack((xn_test, p_test))\n",
        "z_test_good = z_test[z_test[:,-1]==1,:]"
      ],
      "metadata": {
        "id": "WiTqEKr25zC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(p_test[8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCz8DYg_ijTz",
        "outputId": "d3a54109-e97d-465d-8b59-a33ef4b49ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_test_good[8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sdqcfDQi5hV",
        "outputId": "4c759e0c-96d3-455c-d04b-a15543debc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.43617021, -0.24470735, -0.47911227, -0.14643799, -0.03164557,\n",
              "       -0.5       , -0.5       ,  0.5       , -0.5       ,  0.27777778,\n",
              "        0.5       , -0.42307692, -0.44736842, -0.39      ,  0.29166667,\n",
              "       -0.5       , -0.5       , -0.49137931, -0.5       , -0.375     ,\n",
              "       -0.45652174, -0.5       , -0.26      ,  1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#desnormalizando\n",
        "zun_test = np.hstack((x_test, p_test))\n",
        "\n",
        "#Estudo sobre as avaliações \"Good\"\n",
        "zun_test_good=zun_test[zun_test[:,-1]==1,:]"
      ],
      "metadata": {
        "id": "ozxklWdLjHeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Início da avaliação\n",
        "idx=8\n",
        "\n",
        "X=xn_test[idx].reshape((1,) + xn_test[idx].shape)\n",
        "\n",
        "#anexar a predição feita ao X\n",
        "X=np.hstack((X, nn.predict_classes(X).reshape((1,1))))"
      ],
      "metadata": {
        "id": "e-qUgTzej8Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer=ProtodashExplainer()\n",
        "(W, S, setValues) = explainer.explain(X, z_test_good, m=5) # peso W, protótipo S e objetivo"
      ],
      "metadata": {
        "id": "pBPAE_7xlfF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = pd.DataFrame.from_records(zun_test_good[S, 0:-1].astype('double'))\n",
        "RP=[]\n",
        "for i in range(S.shape[0]):\n",
        "  RP.append(class_names[int(z_test_good[S[i],-1])]) #Adiciona os nomes das classes\n",
        "dfs[23]=RP\n",
        "dfs.columns=df.columns\n",
        "dfs['Weight']=np.around(W,5)/np.sum(np.around(W,5)) #Calcula a importancia do peso normalizado\n",
        "dfs.transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "JdhWQ-SGmgpz",
        "outputId": "fb34f77d-086a-4aa7-cd1c-6d26aa460074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        0        1        2        3        4\n",
              "ExternalRiskEstimate                 82.0     86.0     78.0     72.0     89.0\n",
              "MSinceOldestTradeOpen               280.0    315.0    238.0     88.0    474.0\n",
              "MSinceMostRecentTradeOpen            13.0     16.0     40.0      8.0     49.0\n",
              "AverageMInFile                      102.0    102.0    148.0     70.0    184.0\n",
              "NumSatisfactoryTrades                22.0     18.0     31.0     19.0      8.0\n",
              "NumTrades60Ever2DerogPubRec           0.0      1.0      0.0      2.0      0.0\n",
              "NumTrades90Ever2DerogPubRec           0.0      0.0      0.0      2.0      0.0\n",
              "PercentTradesNeverDelq               91.0     95.0    100.0     95.0    100.0\n",
              "MSinceMostRecentDelq                 26.0     64.0      0.0     49.0      0.0\n",
              "MaxDelq2PublicRecLast12M              6.0      6.0      7.0      6.0      7.0\n",
              "MaxDelqEver                           6.0      5.0      8.0      2.0      8.0\n",
              "NumTotalTrades                       23.0     19.0     31.0     20.0     15.0\n",
              "NumTradesOpeninLast12M                0.0      0.0      0.0      1.0      0.0\n",
              "PercentInstallTrades                  9.0     53.0     19.0     10.0      0.0\n",
              "MSinceMostRecentInqexcl7days          0.0      0.0      0.0      0.0      0.0\n",
              "NumInqLast6M                          0.0      5.0      0.0      0.0      0.0\n",
              "NumInqLast6Mexcl7days                 0.0      2.0      0.0      0.0      0.0\n",
              "NetFractionRevolvingBurden            3.0      0.0     65.0      0.0      0.0\n",
              "NetFractionInstallBurden              0.0      0.0     70.0      0.0      0.0\n",
              "NumRevolvingTradesWBalance            4.0      1.0     15.0      0.0      0.0\n",
              "NumInstallTradesWBalance              1.0      1.0      1.0      0.0      0.0\n",
              "NumBank2NatlTradesWHighUtilization    1.0      0.0      6.0      0.0      0.0\n",
              "PercentTradesWBalance                42.0     29.0     94.0      9.0      0.0\n",
              "RiskPerformance                      Good     Good     Good     Good     Good\n",
              "Weight                              0.996  0.00112  0.00105  0.00069  0.00114"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c76e178a-b55d-4280-beb7-2c77c58c4f4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExternalRiskEstimate</th>\n",
              "      <td>82.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>89.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceOldestTradeOpen</th>\n",
              "      <td>280.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>474.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentTradeOpen</th>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AverageMInFile</th>\n",
              "      <td>102.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSatisfactoryTrades</th>\n",
              "      <td>22.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades60Ever2DerogPubRec</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades90Ever2DerogPubRec</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesNeverDelq</th>\n",
              "      <td>91.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentDelq</th>\n",
              "      <td>26.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelq2PublicRecLast12M</th>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelqEver</th>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTotalTrades</th>\n",
              "      <td>23.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTradesOpeninLast12M</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentInstallTrades</th>\n",
              "      <td>9.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentInqexcl7days</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6M</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6Mexcl7days</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionRevolvingBurden</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionInstallBurden</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRevolvingTradesWBalance</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInstallTradesWBalance</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesWBalance</th>\n",
              "      <td>42.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RiskPerformance</th>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>0.996</td>\n",
              "      <td>0.00112</td>\n",
              "      <td>0.00105</td>\n",
              "      <td>0.00069</td>\n",
              "      <td>0.00114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c76e178a-b55d-4280-beb7-2c77c58c4f4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c76e178a-b55d-4280-beb7-2c77c58c4f4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c76e178a-b55d-4280-beb7-2c77c58c4f4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estudo sobre as avaliações \"Bad\"\n",
        "z_test_bad = z_test[z_test[:,-1]==0,:]\n",
        "zun_test_bad=zun_test[zun_test[:,-1]==0,:]"
      ],
      "metadata": {
        "id": "lqi70k6en28E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Início da avaliação\n",
        "idx=8\n",
        "\n",
        "X=xn_test[idx].reshape((1,) + xn_test[idx].shape)\n",
        "\n",
        "#anexar a predição feita ao X\n",
        "X=np.hstack((X, nn.predict_classes(X).reshape((1,1))))"
      ],
      "metadata": {
        "id": "Xsg42HzRsES-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer=ProtodashExplainer()\n",
        "(W, S, setValues) = explainer.explain(X, z_test_bad, m=5) # peso W, protótipo S e objetivo"
      ],
      "metadata": {
        "id": "Oyqq-puaqhJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = pd.DataFrame.from_records(zun_test_bad[S, 0:-1].astype('double'))\n",
        "RP=[]\n",
        "for i in range(S.shape[0]):\n",
        "  RP.append(class_names[int(z_test_bad[S[i],-1])]) #Adiciona os nomes das classes\n",
        "dfs[23]=RP\n",
        "dfs.columns=df.columns\n",
        "dfs['Weight']=np.around(W,5)/np.sum(np.around(W,5)) #Calcula a importancia do peso normalizado\n",
        "dfs.transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "IHQUKADSqhtD",
        "outputId": "8d1c18d9-ba18-4333-e1c1-6e071756f4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          0        1        2         3         4\n",
              "ExternalRiskEstimate                   71.0     67.0     72.0      69.0      64.0\n",
              "MSinceOldestTradeOpen                 291.0    135.0    111.0     390.0     314.0\n",
              "MSinceMostRecentTradeOpen              21.0      0.0    111.0       3.0       4.0\n",
              "AverageMInFile                        108.0     71.0    111.0     100.0      94.0\n",
              "NumSatisfactoryTrades                  23.0     29.0      1.0      18.0      64.0\n",
              "NumTrades60Ever2DerogPubRec             0.0      0.0      1.0       3.0       0.0\n",
              "NumTrades90Ever2DerogPubRec             0.0      0.0      0.0       1.0       0.0\n",
              "PercentTradesNeverDelq                 96.0     94.0      0.0      67.0     100.0\n",
              "MSinceMostRecentDelq                   14.0     80.0     19.0       3.0       0.0\n",
              "MaxDelq2PublicRecLast12M                6.0      6.0      6.0       4.0       7.0\n",
              "MaxDelqEver                             6.0      6.0      5.0       4.0       8.0\n",
              "NumTotalTrades                         23.0     33.0      2.0      11.0      71.0\n",
              "NumTradesOpeninLast12M                  0.0      4.0      0.0       1.0       5.0\n",
              "PercentInstallTrades                   13.0      9.0      0.0      10.0      52.0\n",
              "MSinceMostRecentInqexcl7days            0.0      0.0      0.0      14.0       0.0\n",
              "NumInqLast6M                            2.0      8.0      0.0       0.0       7.0\n",
              "NumInqLast6Mexcl7days                   2.0      8.0      0.0       0.0       7.0\n",
              "NetFractionRevolvingBurden             51.0     35.0      0.0       7.0      82.0\n",
              "NetFractionInstallBurden                0.0     69.0      0.0       0.0      62.0\n",
              "NumRevolvingTradesWBalance              3.0     10.0      0.0       3.0      25.0\n",
              "NumInstallTradesWBalance                1.0      1.0      0.0       0.0      19.0\n",
              "NumBank2NatlTradesWHighUtilization      1.0      2.0      0.0       0.0      15.0\n",
              "PercentTradesWBalance                  44.0     46.0    100.0      27.0      88.0\n",
              "RiskPerformance                         Bad      Bad      Bad       Bad       Bad\n",
              "Weight                              0.56831  0.21614  0.04799  0.133248  0.034313"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dbc3783-16e8-4434-ae74-fa0039f43b16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExternalRiskEstimate</th>\n",
              "      <td>71.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceOldestTradeOpen</th>\n",
              "      <td>291.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>390.0</td>\n",
              "      <td>314.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentTradeOpen</th>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AverageMInFile</th>\n",
              "      <td>108.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>94.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSatisfactoryTrades</th>\n",
              "      <td>23.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades60Ever2DerogPubRec</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades90Ever2DerogPubRec</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesNeverDelq</th>\n",
              "      <td>96.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentDelq</th>\n",
              "      <td>14.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelq2PublicRecLast12M</th>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelqEver</th>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTotalTrades</th>\n",
              "      <td>23.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTradesOpeninLast12M</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentInstallTrades</th>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentInqexcl7days</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6M</th>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6Mexcl7days</th>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionRevolvingBurden</th>\n",
              "      <td>51.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionInstallBurden</th>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRevolvingTradesWBalance</th>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInstallTradesWBalance</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesWBalance</th>\n",
              "      <td>44.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>88.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RiskPerformance</th>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>0.56831</td>\n",
              "      <td>0.21614</td>\n",
              "      <td>0.04799</td>\n",
              "      <td>0.133248</td>\n",
              "      <td>0.034313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dbc3783-16e8-4434-ae74-fa0039f43b16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8dbc3783-16e8-4434-ae74-fa0039f43b16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8dbc3783-16e8-4434-ae74-fa0039f43b16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cálculo deu errado.. Verificar depois\n",
        "z=z_test_bad[S,0:-1] # Armazena os protótipos\n",
        "eps=1e-10 #Constante para evitar divisão por 0\n",
        "fwt=np.zeros(z.shape)\n",
        "for i in range(z.shape[0]):\n",
        "  for j in range(z.shape[1]):\n",
        "    fwt[i,j]=np.exp(-1*abs(X[0,j]-z[i,j]))/(np.std(z[:,j])+eps)\n",
        "\n",
        "#mover o fwt para um dataframe\n",
        "dfw=pd.DataFrame.from_records(np.around(fwt.astype('double'),2))\n",
        "dfw.columns=df.columns[:-1]\n",
        "dfw.transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "UHIHPh5Etcla",
        "outputId": "a553afed-445f-4064-f7ab-3c91aaacf720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        0      1      2      3      4\n",
              "ExternalRiskEstimate                29.13  27.92  29.44  28.52  27.04\n",
              "MSinceOldestTradeOpen                7.36   6.23   6.05   6.51   7.15\n",
              "MSinceMostRecentTradeOpen            8.88   8.76   7.02   8.83   8.86\n",
              "AverageMInFile                      26.24  24.56  26.03  26.52  26.10\n",
              "NumSatisfactoryTrades                3.77   3.49   2.92   3.62   2.24\n",
              "NumTrades60Ever2DerogPubRec         16.29  16.29  15.46  13.91  16.29\n",
              "NumTrades90Ever2DerogPubRec         47.50  47.50  47.50  45.06  47.50\n",
              "PercentTradesNeverDelq               2.53   2.58   1.07   2.09   2.43\n",
              "MSinceMostRecentDelq                 2.46   1.48   2.61   2.15   2.08\n",
              "MaxDelq2PublicRecLast12M             9.19   9.19   9.19   7.36   8.22\n",
              "MaxDelqEver                          4.52   4.52   3.83   3.24   3.24\n",
              "NumTotalTrades                       4.35   3.95   3.55   3.87   2.74\n",
              "NumTradesOpeninLast12M               9.06   7.34   9.06   8.59   6.96\n",
              "PercentInstallTrades                 5.30   5.52   5.04   5.46   3.59\n",
              "MSinceMostRecentInqexcl7days         4.29   4.29   4.29   2.39   4.29\n",
              "NumInqLast6M                        18.61  16.99  19.18  19.18  17.25\n",
              "NumInqLast6Mexcl7days               18.61  16.99  19.18  19.18  17.25\n",
              "NetFractionRevolvingBurden           6.31   6.76   7.66   7.62   5.52\n",
              "NetFractionInstallBurden            14.64  12.65  14.64  14.64  12.84\n",
              "NumRevolvingTradesWBalance           3.44   2.94   3.13   3.44   1.84\n",
              "NumInstallTradesWBalance             3.10   3.10   2.97   2.97   1.42\n",
              "NumBank2NatlTradesWHighUtilization   3.13   2.96   2.96   2.96   1.44\n",
              "PercentTradesWBalance                3.50   3.43   2.00   3.07   2.25"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-354a169e-fec5-442e-b990-401afcaad83d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExternalRiskEstimate</th>\n",
              "      <td>29.13</td>\n",
              "      <td>27.92</td>\n",
              "      <td>29.44</td>\n",
              "      <td>28.52</td>\n",
              "      <td>27.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceOldestTradeOpen</th>\n",
              "      <td>7.36</td>\n",
              "      <td>6.23</td>\n",
              "      <td>6.05</td>\n",
              "      <td>6.51</td>\n",
              "      <td>7.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentTradeOpen</th>\n",
              "      <td>8.88</td>\n",
              "      <td>8.76</td>\n",
              "      <td>7.02</td>\n",
              "      <td>8.83</td>\n",
              "      <td>8.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AverageMInFile</th>\n",
              "      <td>26.24</td>\n",
              "      <td>24.56</td>\n",
              "      <td>26.03</td>\n",
              "      <td>26.52</td>\n",
              "      <td>26.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSatisfactoryTrades</th>\n",
              "      <td>3.77</td>\n",
              "      <td>3.49</td>\n",
              "      <td>2.92</td>\n",
              "      <td>3.62</td>\n",
              "      <td>2.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades60Ever2DerogPubRec</th>\n",
              "      <td>16.29</td>\n",
              "      <td>16.29</td>\n",
              "      <td>15.46</td>\n",
              "      <td>13.91</td>\n",
              "      <td>16.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades90Ever2DerogPubRec</th>\n",
              "      <td>47.50</td>\n",
              "      <td>47.50</td>\n",
              "      <td>47.50</td>\n",
              "      <td>45.06</td>\n",
              "      <td>47.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesNeverDelq</th>\n",
              "      <td>2.53</td>\n",
              "      <td>2.58</td>\n",
              "      <td>1.07</td>\n",
              "      <td>2.09</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentDelq</th>\n",
              "      <td>2.46</td>\n",
              "      <td>1.48</td>\n",
              "      <td>2.61</td>\n",
              "      <td>2.15</td>\n",
              "      <td>2.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelq2PublicRecLast12M</th>\n",
              "      <td>9.19</td>\n",
              "      <td>9.19</td>\n",
              "      <td>9.19</td>\n",
              "      <td>7.36</td>\n",
              "      <td>8.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelqEver</th>\n",
              "      <td>4.52</td>\n",
              "      <td>4.52</td>\n",
              "      <td>3.83</td>\n",
              "      <td>3.24</td>\n",
              "      <td>3.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTotalTrades</th>\n",
              "      <td>4.35</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.55</td>\n",
              "      <td>3.87</td>\n",
              "      <td>2.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTradesOpeninLast12M</th>\n",
              "      <td>9.06</td>\n",
              "      <td>7.34</td>\n",
              "      <td>9.06</td>\n",
              "      <td>8.59</td>\n",
              "      <td>6.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentInstallTrades</th>\n",
              "      <td>5.30</td>\n",
              "      <td>5.52</td>\n",
              "      <td>5.04</td>\n",
              "      <td>5.46</td>\n",
              "      <td>3.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentInqexcl7days</th>\n",
              "      <td>4.29</td>\n",
              "      <td>4.29</td>\n",
              "      <td>4.29</td>\n",
              "      <td>2.39</td>\n",
              "      <td>4.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6M</th>\n",
              "      <td>18.61</td>\n",
              "      <td>16.99</td>\n",
              "      <td>19.18</td>\n",
              "      <td>19.18</td>\n",
              "      <td>17.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6Mexcl7days</th>\n",
              "      <td>18.61</td>\n",
              "      <td>16.99</td>\n",
              "      <td>19.18</td>\n",
              "      <td>19.18</td>\n",
              "      <td>17.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionRevolvingBurden</th>\n",
              "      <td>6.31</td>\n",
              "      <td>6.76</td>\n",
              "      <td>7.66</td>\n",
              "      <td>7.62</td>\n",
              "      <td>5.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionInstallBurden</th>\n",
              "      <td>14.64</td>\n",
              "      <td>12.65</td>\n",
              "      <td>14.64</td>\n",
              "      <td>14.64</td>\n",
              "      <td>12.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRevolvingTradesWBalance</th>\n",
              "      <td>3.44</td>\n",
              "      <td>2.94</td>\n",
              "      <td>3.13</td>\n",
              "      <td>3.44</td>\n",
              "      <td>1.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInstallTradesWBalance</th>\n",
              "      <td>3.10</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.97</td>\n",
              "      <td>2.97</td>\n",
              "      <td>1.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
              "      <td>3.13</td>\n",
              "      <td>2.96</td>\n",
              "      <td>2.96</td>\n",
              "      <td>2.96</td>\n",
              "      <td>1.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesWBalance</th>\n",
              "      <td>3.50</td>\n",
              "      <td>3.43</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.07</td>\n",
              "      <td>2.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-354a169e-fec5-442e-b990-401afcaad83d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-354a169e-fec5-442e-b990-401afcaad83d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-354a169e-fec5-442e-b990-401afcaad83d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Teste de variaveis que poderiam modificar a classificação:\n",
        "\n",
        "idx=20 #caso a ser avaliado\n",
        "\n",
        "X=xn_test[idx].reshape((1,)+xn_test[idx].shape)\n",
        "print(\"Calculando PN para a amostra \",idx)\n",
        "print(\"Predição feita pelo modelo \",nn.predict_proba(X))\n",
        "print(\"Probabilidade predita: \",class_names[np.argmax(nn.predict_proba(X))])\n",
        "print(\"\")\n",
        "\n",
        "mymodel = KerasClassifier(nn)\n",
        "explainer=CEMExplainer(mymodel)\n",
        "\n",
        "arg_mode = 'PN' # Encontrar Pertinent Negatives\n",
        "arg_max_iter = 1000\n",
        "arg_init_const= 10.0\n",
        "arg_b=9 #Número de atualizações para os coeficientes do termo main loss\n",
        "arg_kappa=0.2 #Mínimo intervalo de confiança\n",
        "arg_beta=1e-1 #Controla sparsity da solução\n",
        "arg_gamma= 100 #Controla aderência\n",
        "my_AE_model= None # Apontador do Auto-Encoder\n",
        "arg_alpha=0.01 # Penalizador\n",
        "arg_threshold = 1\n",
        "arg_offset = 0.5\n",
        "\n",
        "(adv_pn, delta_pn, info_pn)=explainer.explain_instance(X, arg_mode, my_AE_model, arg_kappa, arg_b, \n",
        "                                                       arg_max_iter, arg_init_const, arg_beta, arg_gamma, \n",
        "                                                       arg_alpha, arg_threshold, arg_offset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaHsnS7Xyg1A",
        "outputId": "f30b9ef4-e8cd-428e-d0b5-a593910684be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando PN para a amostra  20\n",
            "Predição feita pelo modelo  [[-0.2717616   0.38639238]]\n",
            "Probabilidade predita:  Good\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:151: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:151: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:213: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:213: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:216: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:216: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:230: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:230: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:0 const:[10.]\n",
            "Loss_Overall:0.2162, Loss_Attack:0.0000\n",
            "Loss_L2Dist:0.1287, Loss_L1Dist:0.8751, AE_loss:0.0\n",
            "target_lab_score:-0.7179, max_nontarget_lab_score:0.7858\n",
            "\n",
            "iter:500 const:[10.]\n",
            "Loss_Overall:0.2461, Loss_Attack:0.1801\n",
            "Loss_L2Dist:0.0366, Loss_L1Dist:0.2940, AE_loss:0.0\n",
            "target_lab_score:-0.0428, max_nontarget_lab_score:0.1392\n",
            "\n",
            "iter:0 const:[5.]\n",
            "Loss_Overall:2.6080, Loss_Attack:2.5910\n",
            "Loss_L2Dist:0.0045, Loss_L1Dist:0.1245, AE_loss:0.0\n",
            "target_lab_score:0.2126, max_nontarget_lab_score:-0.1056\n",
            "\n",
            "iter:500 const:[5.]\n",
            "Loss_Overall:2.5727, Loss_Attack:2.5487\n",
            "Loss_L2Dist:0.0127, Loss_L1Dist:0.1128, AE_loss:0.0\n",
            "target_lab_score:0.2089, max_nontarget_lab_score:-0.1009\n",
            "\n",
            "iter:0 const:[2.5]\n",
            "Loss_Overall:2.1454, Loss_Attack:2.1454\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3864, max_nontarget_lab_score:-0.2718\n",
            "\n",
            "iter:500 const:[2.5]\n",
            "Loss_Overall:2.1454, Loss_Attack:2.1454\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3864, max_nontarget_lab_score:-0.2718\n",
            "\n",
            "iter:0 const:[3.75]\n",
            "Loss_Overall:3.0358, Loss_Attack:3.0340\n",
            "Loss_L2Dist:0.0002, Loss_L1Dist:0.0159, AE_loss:0.0\n",
            "target_lab_score:0.3614, max_nontarget_lab_score:-0.2477\n",
            "\n",
            "iter:500 const:[3.75]\n",
            "Loss_Overall:3.2181, Loss_Attack:3.2181\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3864, max_nontarget_lab_score:-0.2718\n",
            "\n",
            "iter:0 const:[4.375]\n",
            "Loss_Overall:3.0803, Loss_Attack:3.0734\n",
            "Loss_L2Dist:0.0015, Loss_L1Dist:0.0529, AE_loss:0.0\n",
            "target_lab_score:0.3068, max_nontarget_lab_score:-0.1957\n",
            "\n",
            "iter:500 const:[4.375]\n",
            "Loss_Overall:3.7544, Loss_Attack:3.7544\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3864, max_nontarget_lab_score:-0.2718\n",
            "\n",
            "iter:0 const:[4.6875]\n",
            "Loss_Overall:2.9055, Loss_Attack:2.8942\n",
            "Loss_L2Dist:0.0028, Loss_L1Dist:0.0853, AE_loss:0.0\n",
            "target_lab_score:0.2634, max_nontarget_lab_score:-0.1541\n",
            "\n",
            "iter:500 const:[4.6875]\n",
            "Loss_Overall:3.7836, Loss_Attack:3.7816\n",
            "Loss_L2Dist:0.0003, Loss_L1Dist:0.0166, AE_loss:0.0\n",
            "target_lab_score:0.3602, max_nontarget_lab_score:-0.2465\n",
            "\n",
            "iter:0 const:[4.53125]\n",
            "Loss_Overall:2.9995, Loss_Attack:2.9905\n",
            "Loss_L2Dist:0.0021, Loss_L1Dist:0.0691, AE_loss:0.0\n",
            "target_lab_score:0.2851, max_nontarget_lab_score:-0.1749\n",
            "\n",
            "iter:500 const:[4.53125]\n",
            "Loss_Overall:3.8885, Loss_Attack:3.8885\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3864, max_nontarget_lab_score:-0.2718\n",
            "\n",
            "iter:0 const:[4.609375]\n",
            "Loss_Overall:2.9541, Loss_Attack:2.9440\n",
            "Loss_L2Dist:0.0024, Loss_L1Dist:0.0772, AE_loss:0.0\n",
            "target_lab_score:0.2742, max_nontarget_lab_score:-0.1645\n",
            "\n",
            "iter:500 const:[4.609375]\n",
            "Loss_Overall:2.6462, Loss_Attack:2.6282\n",
            "Loss_L2Dist:0.0087, Loss_L1Dist:0.0933, AE_loss:0.0\n",
            "target_lab_score:0.2397, max_nontarget_lab_score:-0.1305\n",
            "\n",
            "iter:0 const:[4.6484375]\n",
            "Loss_Overall:2.9302, Loss_Attack:2.9195\n",
            "Loss_L2Dist:0.0026, Loss_L1Dist:0.0813, AE_loss:0.0\n",
            "target_lab_score:0.2688, max_nontarget_lab_score:-0.1593\n",
            "\n",
            "iter:500 const:[4.6484375]\n",
            "Loss_Overall:3.7400, Loss_Attack:3.7379\n",
            "Loss_L2Dist:0.0003, Loss_L1Dist:0.0175, AE_loss:0.0\n",
            "target_lab_score:0.3589, max_nontarget_lab_score:-0.2453\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v0QcTyE41Dme"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}